{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5424fd01-a31f-4288-919f-2d62cce18b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import dask\n",
    "\n",
    "import climate_utils as cu\n",
    "import python_utils as pu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a4a04-9023-4e02-ad7e-83793bdd9cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "### Dask ###\n",
    "############\n",
    "from dask.distributed import LocalCluster\n",
    "\n",
    "cluster = LocalCluster(n_workers=20)\n",
    "\n",
    "client = cluster.get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d58aab-960c-4bcc-9ff4-19fbaebfad4b",
   "metadata": {},
   "source": [
    "## Temperature for load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88852ad-a436-4b9f-b973-515e0561e051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All TGW experiments and bounds\n",
    "tgw_vars = ['T2C']\n",
    "tgw_var_str = tgw_vars[0]\n",
    "\n",
    "tgw_experiments = os.listdir(pu.tgw_path)\n",
    "\n",
    "# Loop through all\n",
    "for tgw_experiment in tgw_experiments:\n",
    "    if os.path.isfile(f\"{pu.project_path}/data/climate/tgw/zonal_{tgw_var_str}_{tgw_experiment}.csv\"):\n",
    "        print(f\"{tgw_experiment} already done\")\n",
    "        continue\n",
    "        \n",
    "    # Extract years\n",
    "    tgw_experiment_yrs_str = tgw_experiment.split('_')[1:]\n",
    "    tgw_years = np.arange(int(tgw_experiment_yrs_str[0]), int(tgw_experiment_yrs_str[1])+1)\n",
    "\n",
    "    # Get paths of all hourly netcdf files\n",
    "    tgw_paths = [glob(f\"{pu.tgw_path}/{tgw_experiment}/hourly/*_{year}-*\") for year in tgw_years]\n",
    "    tgw_paths = [path for sub_path in tgw_paths for path in sub_path] # flatten\n",
    "\n",
    "    # Parallelize with dask\n",
    "    delayed = []\n",
    "    \n",
    "    for path in tgw_paths:\n",
    "        delayed.append(dask.delayed(cu.tgw_to_zones)(path, tgw_vars))\n",
    "    \n",
    "    # Store\n",
    "    df_out = pd.concat(dask.compute(*delayed))\n",
    "    df_out.to_csv(f\"{pu.project_path}/data/climate/tgw/zonal_{tgw_var_str}_{tgw_experiment}.csv\")\n",
    "    print(tgw_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffd5f10-5b1c-49f4-9aa1-35168dcbf168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d69b8cb-83e4-41fd-81cc-9787bda59b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
